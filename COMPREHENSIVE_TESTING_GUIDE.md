# ðŸ§ª COMPREHENSIVE TESTING GUIDE FOR STICKFORSTATS
## Complete Testing Strategy & Validation Framework
### Date: September 17, 2025 | Version: 1.0.0

---

## ðŸ“‹ EXECUTIVE TESTING SUMMARY

### Testing Priorities
1. **50 Decimal Precision Validation** - Our core differentiator
2. **Statistical Accuracy** - Compare with R/Python/SPSS
3. **Example Data System** - All datasets load correctly
4. **ANCOVA Functionality** - New feature validation
5. **End-to-End Integration** - Frontend â†” Backend flow
6. **Performance Testing** - Response times under load
7. **Edge Cases** - Boundary conditions and errors

---

## ðŸŽ¯ SECTION 1: FUNCTIONAL TESTING

### 1.1 T-Test Calculator Testing

#### Test Case 1.1.1: One-Sample T-Test
```javascript
// Steps:
1. Navigate to: http://localhost:3001/statistical-tests
2. Select "T-Test Calculator"
3. Choose "One-Sample T-Test"
4. Click "Load Example Data"
5. Select "Blood Pressure Study"
6. Verify data loads: 30 values starting with 118, 122, 125...
7. Verify hypothesized mean: 120
8. Click "Calculate"

// Expected Results:
âœ“ t-statistic â‰ˆ 2.145 (verify to 50 decimals)
âœ“ p-value < 0.05 (two-tailed)
âœ“ 95% CI should not include 120
âœ“ Effect size (Cohen's d) calculated
âœ“ Assumption checks displayed
âœ“ Export to PDF works
âœ“ Export to CSV works
```

#### Test Case 1.1.2: Paired T-Test
```javascript
// Steps:
1. Select "Paired T-Test"
2. Load "Training Effectiveness" example
3. Verify before/after data pairs
4. Set confidence level to 99%
5. Calculate

// Expected Results:
âœ“ Significant improvement (p < 0.001)
âœ“ Mean difference â‰ˆ 7 points
âœ“ Positive Cohen's d (large effect)
âœ“ All 15 pairs processed
```

#### Test Case 1.1.3: Independent T-Test
```javascript
// Steps:
1. Select "Independent Samples T-Test"
2. Load "Clinical Treatment vs Control" example
3. Toggle Welch's correction ON/OFF
4. Calculate both versions

// Expected Results:
âœ“ Treatment group faster recovery (p < 0.001)
âœ“ Welch's correction slightly different df
âœ“ Levene's test for equal variances
âœ“ Glass's delta calculated
```

### 1.2 ANOVA Calculator Testing

#### Test Case 1.2.1: One-Way ANOVA
```javascript
// Steps:
1. Select "ANOVA Calculator"
2. Choose "One-Way ANOVA"
3. Load "Teaching Methods Comparison" example
4. Select multiple post-hoc tests:
   - Tukey HSD
   - Bonferroni
   - Scheffe
5. Calculate

// Expected Results:
âœ“ F-statistic significant (p < 0.001)
âœ“ Î·Â² (eta-squared) > 0.14 (large effect)
âœ“ Ï‰Â² (omega-squared) calculated
âœ“ All pairwise comparisons shown
âœ“ Hybrid > Online > Traditional
âœ“ Assumption checks: normality, homogeneity
```

#### Test Case 1.2.2: ANCOVA (NEW FEATURE!)
```javascript
// Steps:
1. Choose "ANCOVA" type
2. Load "Salary Analysis with Age Covariate" example
3. Verify groups load (High School, Bachelor's, Master's)
4. Verify covariate loads (Age data)
5. Check "Homogeneity of slopes" checkbox
6. Calculate

// Expected Results:
âœ“ Groups significant after controlling for age
âœ“ Adjusted means displayed
âœ“ Covariate significance shown
âœ“ Homogeneity of slopes test result
âœ“ Partial eta squared calculated
âœ“ Education effect remains after adjustment
```

#### Test Case 1.2.3: Two-Way ANOVA
```javascript
// Steps:
1. Select "Two-Way ANOVA"
2. Manually input 2x3 factorial design data
3. Name factors: "Treatment" and "Dosage"
4. Calculate with interaction

// Expected Results:
âœ“ Main effects for both factors
âœ“ Interaction effect tested
âœ“ Effect sizes for all effects
âœ“ Post-hoc for significant effects
```

### 1.3 Regression Calculator Testing

#### Test Case 1.3.1: Simple Linear Regression
```javascript
// Steps:
1. Select "Regression Calculator"
2. Choose "Linear Regression"
3. Load "Advertising Impact on Sales" example
4. Enable prediction interface
5. Predict for advertising = $5000

// Expected Results:
âœ“ RÂ² > 0.90 (excellent fit)
âœ“ Regression equation displayed
âœ“ Residual plots generated
âœ“ Prediction â‰ˆ $38,000 with CI
âœ“ Durbin-Watson statistic
âœ“ VIF for multicollinearity
```

#### Test Case 1.3.2: Multiple Regression
```javascript
// Steps:
1. Choose "Multiple Regression"
2. Load "House Price Prediction" example
3. Check all diagnostic plots
4. Request standardized coefficients

// Expected Results:
âœ“ All predictors' p-values shown
âœ“ Adjusted RÂ² calculated
âœ“ Multicollinearity checks (VIF)
âœ“ Residual normality tested
âœ“ Cook's distance for outliers
```

#### Test Case 1.3.3: Logistic Regression
```javascript
// Steps:
1. Choose "Logistic Regression"
2. Load "Credit Default Prediction" example
3. Set classification threshold to 0.5
4. Calculate

// Expected Results:
âœ“ Odds ratios displayed
âœ“ ROC curve generated
âœ“ AUC > 0.8
âœ“ Confusion matrix shown
âœ“ Sensitivity/Specificity calculated
```

### 1.4 Correlation Calculator Testing

#### Test Case 1.4.1: Pearson Correlation
```javascript
// Steps:
1. Select "Correlation Calculator"
2. Load "Temperature vs Ice Cream Sales" example
3. Choose Pearson method
4. Enable bootstrap CI (1000 iterations)

// Expected Results:
âœ“ r â‰ˆ 0.98 (very strong positive)
âœ“ p-value < 0.001
âœ“ 95% CI: [0.94, 0.99]
âœ“ Scatterplot with trend line
âœ“ RÂ² = 0.96
```

#### Test Case 1.4.2: Correlation Matrix
```javascript
// Steps:
1. Select "Matrix Correlation"
2. Input 4+ variables
3. Choose Spearman method
4. Apply Bonferroni correction

// Expected Results:
âœ“ Full correlation matrix displayed
âœ“ Heat map visualization
âœ“ Adjusted p-values shown
âœ“ Significant correlations highlighted
```

### 1.5 Non-Parametric Tests

#### Test Case 1.5.1: Mann-Whitney U Test
```javascript
// Steps:
1. Select "Non-Parametric Tests"
2. Choose "Mann-Whitney U"
3. Load "Customer Satisfaction Ratings" example
4. Calculate with exact p-value

// Expected Results:
âœ“ U statistic calculated
âœ“ Z-score approximation
âœ“ Effect size (rank-biserial)
âœ“ Service A > Service B confirmed
```

#### Test Case 1.5.2: Kruskal-Wallis Test
```javascript
// Steps:
1. Choose "Kruskal-Wallis"
2. Load "Brand Preference Rankings" example
3. Enable post-hoc comparisons
4. Calculate

// Expected Results:
âœ“ H statistic significant
âœ“ Chi-square approximation
âœ“ Dunn's post-hoc tests
âœ“ Effect size (epsilon squared)
```

### 1.6 Categorical Tests

#### Test Case 1.6.1: Chi-Square Independence
```javascript
// Steps:
1. Select "Categorical Tests"
2. Choose "Chi-Square Independence"
3. Load "Gender vs Product Preference" example
4. Calculate with Yates correction

// Expected Results:
âœ“ Ï‡Â² statistic > critical value
âœ“ p-value < 0.05
âœ“ Cramer's V effect size
âœ“ Expected frequencies shown
âœ“ Standardized residuals
```

#### Test Case 1.6.2: Fisher's Exact Test
```javascript
// Steps:
1. Choose "Fisher's Exact Test"
2. Load "Treatment Efficacy (Small Sample)" example
3. Calculate both one and two-tailed

// Expected Results:
âœ“ Exact p-value calculated
âœ“ Odds ratio with CI
âœ“ More accurate than chi-square for small n
```

---

## ðŸ”¬ SECTION 2: PRECISION TESTING

### 2.1 50 Decimal Precision Validation

#### Test Case 2.1.1: Backend Precision
```python
# Python test script
import requests
import mpmath

# Set precision to 50
mpmath.mp.dps = 50

# Test data
data = {
    "sample1": [1.23456789012345678901234567890123456789012345678901],
    "sample2": [2.34567890123456789012345678901234567890123456789012]
}

# Call API
response = requests.post('http://localhost:8000/api/v1/stats/ttest/', json=data)
result = response.json()

# Verify precision maintained
assert len(str(result['t_statistic']).split('.')[-1]) >= 40
print(f"âœ“ Backend maintains {len(str(result['t_statistic']).split('.')[-1])} decimal places")
```

#### Test Case 2.1.2: Frontend Display
```javascript
// Steps:
1. Perform any calculation
2. Set display precision to "50 decimals (Maximum)"
3. Click "Show Full Precision"
4. Copy value to clipboard
5. Paste in text editor

// Verification:
âœ“ Count decimal places (should be 50)
âœ“ No rounding errors visible
âœ“ Consistent across all calculators
```

#### Test Case 2.1.3: End-to-End Precision
```javascript
// Critical precision test
Input: Ï€ = 3.14159265358979323846264338327950288419716939937510

// Test in each calculator:
1. T-Test: Use as hypothesized mean
2. ANOVA: Use in group data
3. Regression: Use as predictor value
4. Correlation: Use in dataset

// Verify:
âœ“ All 50 digits preserved in results
âœ“ No precision loss in calculations
âœ“ Export maintains precision
```

---

## ðŸ“Š SECTION 3: INTEGRATION TESTING

### 3.1 Example Data System

#### Test Case 3.1.1: Data Loader Component
```javascript
// For EACH calculator:
1. Click "Load Example Data"
2. Verify dialog opens
3. Select each available dataset
4. Verify preview shows correctly
5. Load data
6. Verify data populates correctly

// Checklist:
â–¡ T-Test: 6 example datasets
â–¡ ANOVA: 4 example datasets
â–¡ ANCOVA: 2 example datasets
â–¡ Regression: 5 example datasets
â–¡ Correlation: 3 example datasets
â–¡ Non-Parametric: 4 example datasets
â–¡ Categorical: 4 example datasets
```

#### Test Case 3.1.2: Data Integrity
```javascript
// Verify each dataset:
âœ“ Correct number of observations
âœ“ Expected outcome matches actual result
âœ“ Context label appropriate
âœ“ Description accurate
âœ“ No missing values (unless intentional)
```

### 3.2 API Integration

#### Test Case 3.2.1: Authentication Flow
```bash
# Test API authentication
curl -X POST http://localhost:8000/api/v1/auth/login/ \
  -H "Content-Type: application/json" \
  -d '{"username": "test", "password": "test"}'

# Use token in subsequent requests
curl -X POST http://localhost:8000/api/v1/stats/ttest/ \
  -H "Authorization: Token <token>" \
  -H "Content-Type: application/json" \
  -d '{"sample1": [1,2,3], "sample2": [4,5,6]}'
```

#### Test Case 3.2.2: Error Handling
```javascript
// Test invalid inputs:
1. Empty data arrays
2. Single data point
3. Non-numeric values
4. Mismatched array lengths
5. Missing required fields

// Expected:
âœ“ Graceful error messages
âœ“ No crashes
âœ“ Clear user guidance
âœ“ Form validation works
```

---

## ðŸš€ SECTION 4: PERFORMANCE TESTING

### 4.1 Response Time Testing

#### Test Case 4.1.1: Calculation Speed
```javascript
// Benchmark each test type:
Dataset Size    Expected Time
10 points       < 100ms
100 points      < 500ms
1000 points     < 2 seconds
10000 points    < 10 seconds

// Test with Chrome DevTools:
1. Open Network tab
2. Perform calculation
3. Check API response time
4. Check rendering time
```

### 4.2 Load Testing

#### Test Case 4.2.1: Concurrent Users
```python
# Load test with locust
from locust import HttpUser, task, between

class StickForStatsUser(HttpUser):
    wait_time = between(1, 3)

    @task
    def perform_ttest(self):
        self.client.post("/api/v1/stats/ttest/", json={
            "sample1": [1,2,3,4,5],
            "sample2": [6,7,8,9,10]
        })

    @task
    def perform_anova(self):
        self.client.post("/api/v1/stats/anova/", json={
            "groups": [[1,2,3], [4,5,6], [7,8,9]]
        })

# Run: locust -f loadtest.py --host=http://localhost:8000
# Target: 100 concurrent users, 0% error rate
```

---

## ðŸ›¡ï¸ SECTION 5: SECURITY TESTING

### 5.1 Input Validation

#### Test Case 5.1.1: SQL Injection Prevention
```javascript
// Test malicious inputs:
1. Group name: "'; DROP TABLE users; --"
2. Data values: "<script>alert('XSS')</script>"
3. File upload: malicious.exe renamed to .csv

// Verify:
âœ“ All inputs sanitized
âœ“ No script execution
âœ“ File type validation works
```

### 5.2 Authentication Security

#### Test Case 5.2.1: Token Security
```javascript
// Test:
1. Token expiration
2. Invalid token rejection
3. Rate limiting on login
4. Password complexity requirements
```

---

## ðŸŽ¨ SECTION 6: UI/UX TESTING

### 6.1 Responsive Design

#### Test Case 6.1.1: Mobile Compatibility
```javascript
// Test on devices:
â–¡ iPhone 12/13/14
â–¡ Samsung Galaxy S21
â–¡ iPad Pro
â–¡ Desktop (1920x1080)
â–¡ Desktop (4K)

// Check:
âœ“ All buttons clickable
âœ“ Tables scroll horizontally
âœ“ Modals fit screen
âœ“ Text readable
```

### 6.2 Accessibility

#### Test Case 6.2.1: WCAG Compliance
```javascript
// Test with tools:
1. Run Lighthouse audit
2. Test with screen reader (NVDA/JAWS)
3. Keyboard-only navigation
4. Color contrast checker

// Target:
âœ“ Lighthouse score > 90
âœ“ All interactive elements focusable
âœ“ ARIA labels present
âœ“ Contrast ratio â‰¥ 4.5:1
```

---

## ðŸ“ˆ SECTION 7: STATISTICAL VALIDATION

### 7.1 Cross-Validation with R

#### Test Case 7.1.1: T-Test Validation
```r
# R validation script
data1 <- c(1, 2, 3, 4, 5)
data2 <- c(6, 7, 8, 9, 10)

# R result
t.test(data1, data2)

# Compare with StickForStats result
# Difference should be < 10^-10
```

### 7.2 Python (SciPy) Validation

#### Test Case 7.2.1: ANOVA Validation
```python
from scipy import stats
import numpy as np

# Test data
group1 = [72, 75, 68, 70, 73]
group2 = [78, 82, 80, 79, 81]
group3 = [85, 88, 86, 87, 89]

# SciPy result
f_stat, p_val = stats.f_oneway(group1, group2, group3)

# Compare with StickForStats
# Our precision should exceed SciPy's float64
```

---

## ðŸ› SECTION 8: BUG TRACKING

### Known Issues to Test

```yaml
Issue #1:
  Description: ListItemButton import warning in RegressionCalculator
  Status: Verify fixed
  Test: Check console for errors

Issue #2:
  Description: Source map warnings
  Status: Non-critical, can ignore
  Test: Verify doesn't affect functionality

Issue #3:
  Description: Multiple background processes on port 3001
  Status: Monitor for port conflicts
  Test: Check with lsof -i :3001
```

---

## ðŸ“ SECTION 9: TEST EXECUTION CHECKLIST

### Phase 1: Smoke Testing (30 min)
```
â–¡ Frontend loads without errors
â–¡ Backend API responds
â–¡ Each calculator opens
â–¡ Basic calculation works
â–¡ Example data loads
```

### Phase 2: Feature Testing (2 hours)
```
â–¡ All T-Test variants
â–¡ All ANOVA types (including ANCOVA)
â–¡ All Regression types
â–¡ Correlation methods
â–¡ Non-parametric tests
â–¡ Categorical tests
â–¡ Export functionality
â–¡ Precision validation
```

### Phase 3: Integration Testing (1 hour)
```
â–¡ Example data system
â–¡ API endpoints
â–¡ Authentication flow
â–¡ Error handling
â–¡ Data persistence
```

### Phase 4: Performance Testing (30 min)
```
â–¡ Response times
â–¡ Large dataset handling
â–¡ Concurrent users
â–¡ Memory usage
```

### Phase 5: Final Validation (30 min)
```
â–¡ Cross-check with R/Python
â–¡ Verify 50 decimal precision
â–¡ Export formats correct
â–¡ Documentation complete
```

---

## ðŸŽ¯ TESTING PRIORITIES

### MUST TEST (Critical)
1. **50 decimal precision** - Core differentiator
2. **ANCOVA functionality** - New feature
3. **Example data loading** - User experience
4. **Basic calculations** - All calculators
5. **Export functionality** - PDF/CSV

### SHOULD TEST (Important)
1. Post-hoc tests
2. Assumption checking
3. Effect sizes
4. Visualization
5. Error handling

### NICE TO TEST (Enhancement)
1. Performance optimization
2. Mobile responsiveness
3. Accessibility
4. Cross-browser compatibility
5. Localization

---

## ðŸ“Š TEST METRICS

### Success Criteria
```yaml
Functional Tests:     100% pass
Precision Tests:      50 decimals maintained
Integration Tests:    95% pass
Performance Tests:    <2s for standard operations
Security Tests:       No vulnerabilities
UI/UX Tests:         >90 Lighthouse score
Statistical Tests:    <10^-10 difference from R/Python
```

---

## ðŸš€ QUICK TEST SCRIPT

```bash
#!/bin/bash
# Quick smoke test script

echo "ðŸ§ª Starting StickForStats Quick Test..."

# Check backend
echo "Testing backend..."
curl -s http://localhost:8000/api/health/ || echo "âŒ Backend not responding"

# Check frontend
echo "Testing frontend..."
curl -s http://localhost:3001/ || echo "âŒ Frontend not responding"

# Test simple calculation
echo "Testing calculation..."
curl -X POST http://localhost:8000/api/v1/stats/ttest/ \
  -H "Content-Type: application/json" \
  -d '{"sample1": [1,2,3], "sample2": [4,5,6], "test_type": "independent"}' \
  || echo "âŒ Calculation failed"

echo "âœ… Quick test complete!"
```

---

## ðŸ“± MANUAL TESTING WORKFLOW

### For Each Calculator:
1. **Open Calculator**
   - Verify UI loads correctly
   - Check all tabs/sections visible

2. **Load Example Data**
   - Click "Load Example Data"
   - Select dataset
   - Verify preview
   - Load into calculator

3. **Run Calculation**
   - Click Calculate
   - Verify results appear
   - Check assumptions
   - Verify precision

4. **Test Features**
   - Change parameters
   - Try different methods
   - Test edge cases

5. **Export Results**
   - Export to PDF
   - Export to CSV
   - Verify formatting

---

## ðŸŽ‰ TESTING COMPLETION

### Sign-off Checklist
```
â–¡ All functional tests passed
â–¡ 50 decimal precision verified
â–¡ ANCOVA working correctly
â–¡ Example data system functional
â–¡ No critical bugs found
â–¡ Performance acceptable
â–¡ Documentation updated
â–¡ Ready for deployment
```

---

**Document Generated**: September 17, 2025
**Testing Framework**: Version 1.0.0
**Next Review**: Before major release

---

*"Quality is not an act, it is a habit." - Aristotle*

## TEST WITH CONFIDENCE. SHIP WITH PRIDE. ðŸš€